See Moleskine notebook for addt'l notes and drawings where indicated

##### Chapter 1 #####
- use the PyMC3 version for Python 3
- Bayesian vs. Frequentist
	- The Bayesian world-view interprets probability as measure of believability in an event, that is, how confident we are in an event occurring. 
	- Frequentist, known as the more classical version of statistics, assume that probability is the long-run frequency of events (hence the bestowed title).
		- probability of an event is the long-run probabilty of an event (law of large numbers)
	- Bayesians allow for individuals to have differing beliefs about a probability, rather than it being a product of nature
	- probability A without any new information is always the prior for a Bayesian P(A), adding info X to that probability leads to the posterior probability P(A|X)
		- generating the posterior can also be thought of as reweighting the prior A with evidence X to P(A|X)

	- Interpretation of statistical problems/results
		- frequentists look at some derived test statistic and see if it's extreme enough to reject the Null hypothesis
		- bayesians get an update probability (belief) about the problem
			- EX from Book:
				- If frequentist and Bayesian inference were programming functions, with inputs being statistical problems, then the two would be different in what they return to the user. The frequentist inference function would return a number, representing an estimate (typically a summary statistic like the sample average etc.), whereas the Bayesian function would return probabilities.
				- For example, in our debugging problem above, calling the frequentist function with the argument "My code passed all  XX  tests; is my code bug-free?" would return a YES. On the other hand, asking our Bayesian function "Often my code has bugs. My code passed all  XX  tests; is my code bug-free?" would return something very different: probabilities of YES and NO. The function might return: YES, with probability 0.8; NO, with probability 0.2

	- As instances of evidence (N) approaches infinity, bayesian results represent frequentist results. However, with low N, frequentist results have lots of variance and thus high conf. limits so bayesian is better. 

- Bayes Thereom: P(A|X)=P(X|A)P(A)/P(X)

- Coding Bug Example:
	- P(A) = probability of the event there are NO bugs, also denoted as variable p
	- P(A|X) = probability of the event there are NO bugs, conditional on passing test X
		- 1 - P(A|X) = probability of passing text X despite there being a bug
	- P(X|A) = Probability of passing test X, conditional on NO bugs (always 1)
	- P(X) = P(X|A)P(A) + P(X|~A)P(~A)
		- P(X|~A) = probability of passing test X, conditional on there BEING bugs. This is subjective and may come from our knowledge of tests etc.
	- see chart for nice example of relation between prior and posterior in this example

- PDFs
	- good example of how to describe a pdf is: a probability distribution is a curve where the probability of an outcome is proportional to the height of the curve.
		- use of proportional here is good b/c people always wonder what the denisty number means
- RVs
	- three types
		- discrete
		- continuous 
		- mixed: assign probabilitys to both continuous and discrete variables
	- poisson
		- increase lamda increase probability of higher counts, decrease lambda decreases probablity
		- lambda can be any positive number
		- however, k must be an integer 
	- exponential
		- continuous
		- good choice for time, temperature, or other precise/positive data
		- fz(z|λ)=λe^−λz,  z≥0
		- expected value is equal to inverse of λ: E[z|λ] = 1/λ 

- texting example
	- switchpoint: a point in time when the parameter of an RV (e.g. lambda for poisson) changes during a time series of values from that RV (or could change across another dimension e.g. space)
	- it looks like texting rate may have increased in second half of data so there may be a switchpoint
	- we want to estimate lamda for a poisson RV for each half of the time series, if there was no switchpoint than the lambdas should be similar/the same
		- however, to estimate lamda we need a distribution of possible values for that parameter 	
		- we can use the exponential distribution described above for this since it takes a value of any real positive integer
		- the value defining the exponential distribution here, a, is called a hyper-parameter b/c it defines other parameters (lambda)
		- see text for setting value of alpha for exponential
	- unknown parameters are lambda, a, and which time period lambda changes in


To Do :
- Install Theano. This seems like a bitch




	
